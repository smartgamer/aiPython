{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import visualize_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Argument parser \n",
    "def build_arg_parser():\n",
    "    parser = argparse.ArgumentParser(description='Classify data using \\\n",
    "            Ensemble Learning techniques')\n",
    "    parser.add_argument('--classifier-type', dest='classifier_type', \n",
    "            required=True, choices=['rf', 'erf'], help=\"Type of classifier \\\n",
    "                    to use; can be either 'rf' or 'erf'\")\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    # Parse the input arguments\n",
    "    args = build_arg_parser().parse_args()\n",
    "    classifier_type = args.classifier_type\n",
    "\n",
    "    # Load input data\n",
    "    input_file = 'data_random_forests.txt'\n",
    "    data = np.loadtxt(input_file, delimiter=',')\n",
    "    X, y = data[:, :-1], data[:, -1]\n",
    "\n",
    "    # Separate input data into three classes based on labels\n",
    "    class_0 = np.array(X[y==0])\n",
    "    class_1 = np.array(X[y==1])\n",
    "    class_2 = np.array(X[y==2])\n",
    "\n",
    "    # Visualize input data\n",
    "    plt.figure()\n",
    "    plt.scatter(class_0[:, 0], class_0[:, 1], s=75, facecolors='white', \n",
    "                    edgecolors='black', linewidth=1, marker='s')\n",
    "    plt.scatter(class_1[:, 0], class_1[:, 1], s=75, facecolors='white', \n",
    "                    edgecolors='black', linewidth=1, marker='o')\n",
    "    plt.scatter(class_2[:, 0], class_2[:, 1], s=75, facecolors='white', \n",
    "                    edgecolors='black', linewidth=1, marker='^')\n",
    "    plt.title('Input data')\n",
    "\n",
    "    # Split data into training and testing datasets \n",
    "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(\n",
    "            X, y, test_size=0.25, random_state=5)\n",
    "\n",
    "    # Ensemble Learning classifier\n",
    "    params = {'n_estimators': 100, 'max_depth': 4, 'random_state': 0}\n",
    "    if classifier_type == 'rf':\n",
    "        classifier = RandomForestClassifier(**params)\n",
    "    else:\n",
    "        classifier = ExtraTreesClassifier(**params)\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "    visualize_classifier(classifier, X_train, y_train, 'Training dataset')\n",
    "\n",
    "    y_test_pred = classifier.predict(X_test)\n",
    "    visualize_classifier(classifier, X_test, y_test, 'Test dataset')\n",
    "\n",
    "    # Evaluate classifier performance\n",
    "    class_names = ['Class-0', 'Class-1', 'Class-2']\n",
    "    print(\"\\n\" + \"#\"*40)\n",
    "    print(\"\\nClassifier performance on training dataset\\n\")\n",
    "    print(classification_report(y_train, classifier.predict(X_train), target_names=class_names))\n",
    "    print(\"#\"*40 + \"\\n\")\n",
    "\n",
    "    print(\"#\"*40)\n",
    "    print(\"\\nClassifier performance on test dataset\\n\")\n",
    "    print(classification_report(y_test, y_test_pred, target_names=class_names))\n",
    "    print(\"#\"*40 + \"\\n\")\n",
    "\n",
    "    # Compute confidence\n",
    "    test_datapoints = np.array([[5, 5], [3, 6], [6, 4], [7, 2], [4, 4], [5, 2]])\n",
    "\n",
    "    print(\"\\nConfidence measure:\")\n",
    "    for datapoint in test_datapoints:\n",
    "        probabilities = classifier.predict_proba([datapoint])[0]\n",
    "        predicted_class = 'Class-' + str(np.argmax(probabilities))\n",
    "        print('\\nDatapoint:', datapoint)\n",
    "        print('Predicted class:', predicted_class) \n",
    "\n",
    "    # Visualize the datapoints\n",
    "    visualize_classifier(classifier, test_datapoints, [0]*len(test_datapoints), \n",
    "            'Test datapoints')\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
