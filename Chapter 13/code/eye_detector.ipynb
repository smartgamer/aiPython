{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Haar cascade files for face and eye\n",
    "face_cascade = cv2.CascadeClassifier('haar_cascade_files/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haar_cascade_files/haarcascade_eye.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the face cascade file has been loaded correctly\n",
    "if face_cascade.empty():\n",
    "\traise IOError('Unable to load the face cascade classifier xml file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the eye cascade file has been loaded correctly\n",
    "if eye_cascade.empty():\n",
    "\traise IOError('Unable to load the eye cascade classifier xml file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the video capture object\n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scaling factor\n",
    "ds_factor = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate until the user hits the 'Esc' key\n",
    "while True:\n",
    "    # Capture the current frame\n",
    "    _, frame = cap.read()\n",
    "\n",
    "    # Resize the frame\n",
    "    frame = cv2.resize(frame, None, fx=ds_factor, fy=ds_factor, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Run the face detector on the grayscale image\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    # For each face that's detected, run the eye detector\n",
    "    for (x,y,w,h) in faces:\n",
    "        # Extract the grayscale face ROI\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "\n",
    "        # Extract the color face ROI\n",
    "        roi_color = frame[y:y+h, x:x+w]\n",
    "\n",
    "        # Run the eye detector on the grayscale ROI\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "\n",
    "        # Draw circles around the eyes\n",
    "        for (x_eye,y_eye,w_eye,h_eye) in eyes:\n",
    "            center = (int(x_eye + 0.5*w_eye), int(y_eye + 0.5*h_eye))\n",
    "            radius = int(0.3 * (w_eye + h_eye))\n",
    "            color = (0, 255, 0)\n",
    "            thickness = 3\n",
    "            cv2.circle(roi_color, center, radius, color, thickness)\n",
    "\n",
    "    # Display the output\n",
    "    cv2.imshow('Eye Detector', frame)\n",
    "\n",
    "    # Check if the user hit the 'Esc' key\n",
    "    c = cv2.waitKey(1)\n",
    "    if c == 27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release the video capture object\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close all the windows\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
