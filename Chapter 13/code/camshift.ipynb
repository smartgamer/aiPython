{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class to handle object tracking related functionality\n",
    "class ObjectTracker(object):\n",
    "    def __init__(self, scaling_factor=0.5):\n",
    "        # Initialize the video capture object\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "\n",
    "        # Capture the frame from the webcam\n",
    "        _, self.frame = self.cap.read()\n",
    "\n",
    "        # Scaling factor for the captured frame\n",
    "        self.scaling_factor = scaling_factor\n",
    "\n",
    "        # Resize the frame\n",
    "        self.frame = cv2.resize(self.frame, None, \n",
    "                fx=self.scaling_factor, fy=self.scaling_factor, \n",
    "                interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        # Create a window to display the frame\n",
    "        cv2.namedWindow('Object Tracker')\n",
    "\n",
    "        # Set the mouse callback function to track the mouse\n",
    "        cv2.setMouseCallback('Object Tracker', self.mouse_event)\n",
    "\n",
    "        # Initialize variable related to rectangular region selection\n",
    "        self.selection = None\n",
    "\n",
    "        # Initialize variable related to starting position \n",
    "        self.drag_start = None\n",
    "\n",
    "        # Initialize variable related to the state of tracking \n",
    "        self.tracking_state = 0\n",
    "\n",
    "    # Define a method to track the mouse events\n",
    "    def mouse_event(self, event, x, y, flags, param):\n",
    "        # Convert x and y coordinates into 16-bit numpy integers\n",
    "        x, y = np.int16([x, y]) \n",
    "\n",
    "        # Check if a mouse button down event has occurred\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            self.drag_start = (x, y)\n",
    "            self.tracking_state = 0\n",
    "\n",
    "        # Check if the user has started selecting the region\n",
    "        if self.drag_start:\n",
    "            if flags & cv2.EVENT_FLAG_LBUTTON:\n",
    "                # Extract the dimensions of the frame\n",
    "                h, w = self.frame.shape[:2]\n",
    "\n",
    "                # Get the initial position\n",
    "                xi, yi = self.drag_start\n",
    "\n",
    "                # Get the max and min values\n",
    "                x0, y0 = np.maximum(0, np.minimum([xi, yi], [x, y]))\n",
    "                x1, y1 = np.minimum([w, h], np.maximum([xi, yi], [x, y]))\n",
    "\n",
    "                # Reset the selection variable\n",
    "                self.selection = None\n",
    "\n",
    "                # Finalize the rectangular selection\n",
    "                if x1-x0 > 0 and y1-y0 > 0:\n",
    "                    self.selection = (x0, y0, x1, y1)\n",
    "\n",
    "            else:\n",
    "                # If the selection is done, start tracking  \n",
    "                self.drag_start = None\n",
    "                if self.selection is not None:\n",
    "                    self.tracking_state = 1\n",
    "\n",
    "    # Method to start tracking the object\n",
    "    def start_tracking(self):\n",
    "        # Iterate until the user presses the Esc key\n",
    "        while True:\n",
    "            # Capture the frame from webcam\n",
    "            _, self.frame = self.cap.read()\n",
    "            \n",
    "            # Resize the input frame\n",
    "            self.frame = cv2.resize(self.frame, None, \n",
    "                    fx=self.scaling_factor, fy=self.scaling_factor, \n",
    "                    interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            # Create a copy of the frame\n",
    "            vis = self.frame.copy()\n",
    "\n",
    "            # Convert the frame to HSV colorspace\n",
    "            hsv = cv2.cvtColor(self.frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "            # Create the mask based on predefined thresholds\n",
    "            mask = cv2.inRange(hsv, np.array((0., 60., 32.)), \n",
    "                        np.array((180., 255., 255.)))\n",
    "\n",
    "            # Check if the user has selected the region\n",
    "            if self.selection:\n",
    "                # Extract the coordinates of the selected rectangle\n",
    "                x0, y0, x1, y1 = self.selection\n",
    "\n",
    "                # Extract the tracking window\n",
    "                self.track_window = (x0, y0, x1-x0, y1-y0)\n",
    "\n",
    "                # Extract the regions of interest \n",
    "                hsv_roi = hsv[y0:y1, x0:x1]\n",
    "                mask_roi = mask[y0:y1, x0:x1]\n",
    "\n",
    "                # Compute the histogram of the region of \n",
    "                # interest in the HSV image using the mask\n",
    "                hist = cv2.calcHist( [hsv_roi], [0], mask_roi, \n",
    "                        [16], [0, 180] )\n",
    "\n",
    "                # Normalize and reshape the histogram\n",
    "                cv2.normalize(hist, hist, 0, 255, cv2.NORM_MINMAX);\n",
    "                self.hist = hist.reshape(-1)\n",
    "\n",
    "                # Extract the region of interest from the frame\n",
    "                vis_roi = vis[y0:y1, x0:x1]\n",
    "\n",
    "                # Compute the image negative (for display only)\n",
    "                cv2.bitwise_not(vis_roi, vis_roi)\n",
    "                vis[mask == 0] = 0\n",
    "\n",
    "            # Check if the system in the \"tracking\" mode\n",
    "            if self.tracking_state == 1:\n",
    "                # Reset the selection variable\n",
    "                self.selection = None\n",
    "                \n",
    "                # Compute the histogram back projection\n",
    "                hsv_backproj = cv2.calcBackProject([hsv], [0], \n",
    "                        self.hist, [0, 180], 1)\n",
    "\n",
    "                # Compute bitwise AND between histogram \n",
    "                # backprojection and the mask\n",
    "                hsv_backproj &= mask\n",
    "\n",
    "                # Define termination criteria for the tracker\n",
    "                term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, \n",
    "                        10, 1)\n",
    "\n",
    "                # Apply CAMShift on 'hsv_backproj'\n",
    "                track_box, self.track_window = cv2.CamShift(hsv_backproj, \n",
    "                        self.track_window, term_crit)\n",
    "\n",
    "                # Draw an ellipse around the object\n",
    "                cv2.ellipse(vis, track_box, (0, 255, 0), 2)\n",
    "\n",
    "            # Show the output live video\n",
    "            cv2.imshow('Object Tracker', vis)\n",
    "\n",
    "            # Stop if the user hits the 'Esc' key\n",
    "            c = cv2.waitKey(5)\n",
    "            if c == 27:\n",
    "                break\n",
    "\n",
    "        # Close all the windows\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\t# Start the tracker\n",
    "    ObjectTracker().start_tracking()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
